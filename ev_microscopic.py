import streamlit as st
import cv2
import numpy as np
import tensorflow as tf
from PIL import Image
import os
import io

# --- 1. Streamlit Configuration ---
st.set_page_config(
    page_title="Pinworm Disease Diagnosis",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("üî¨ Pinworm Disease Diagnosis App")
st.header("‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö!")
st.markdown("""
‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö **‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡πÄ‡∏Ç‡πá‡∏°‡∏´‡∏°‡∏∏‡∏î (_Enterobius vermicularis_)**
‡πÇ‡∏õ‡∏£‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏°‡∏ô‡∏π‡∏ó‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£:
""")

# Using object notation for sidebar navigation
add_selectbox = st.sidebar.selectbox(
    "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏°‡∏ô‡∏π‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:",
    ("‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å/‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡πÄ‡∏Ç‡πá‡∏°‡∏´‡∏°‡∏∏‡∏î", "üîé AI detection", "Dataset")
)

# --- 2. Model Loading (Cached for Efficiency) ---
@st.cache_resource()
def load_model():
    # NOTE: In a real environment, 'ev_cnn_mobile.keras' must be present in the directory.
    model_path = 'ev_cnn_mobile.keras'
    try:
        model = tf.keras.models.load_model(model_path, custom_objects={'mse': tf.keras.losses.MeanSquaredError()})
        return model
    except FileNotFoundError:
        st.error(f"Error: Model file not found at path '{model_path}'. Please ensure 'ev_cnn_mobile.keras' is in the current directory.")
        return None
    except Exception as e:
        st.error(f"Error loading model: {e}")
        return None

# Load the model using the cached function
model = load_model()

class_label = ["Artifact", "Ev eggs"]

# --- 3. Helper Functions ---

def drawbox(img, label, a, b, c, d, color):
    # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î Font ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏û
    image = cv2.rectangle(img, (c, a), (d, b), color, 3)
    image = cv2.putText(image, label, (c, a - 10), cv2.FONT_HERSHEY_TRIPLEX, 3, color, 3)
    return image

def compute_iou(box1, box2):
    y1 = max(box1[0], box2[0])
    y2 = min(box1[1], box2[1])
    x1 = max(box1[2], box2[2])
    x2 = min(box1[3], box2[3])
    inter_w = max(0, x2 - x1)
    inter_h = max(0, y2 - y1)
    inter_area = inter_w * inter_h
    box1_area = (box1[1] - box1[0]) * (box1[3] - box1[2])
    box2_area = (box2[1] - box2[0]) * (box2[3] - box2[2])
    union_area = box1_area + box2_area - inter_area
    if union_area == 0:
        return 0
    return inter_area / union_area

def nms(detections, iou_threshold):
    nms_dets = []
    if not detections:
        return []
        
    class_indices = set([d['class_idx'] for d in detections])
    for class_idx in class_indices:
        class_dets = [d for d in detections if d['class_idx'] == class_idx]
        class_dets = sorted(class_dets, key=lambda x: x['score'], reverse=True)
        keep = []
        while class_dets:
            curr = class_dets.pop(0)
            keep.append(curr)
            class_dets = [
                d for d in class_dets
                if compute_iou(curr['bbox'], d['bbox']) < iou_threshold
            ]
        nms_dets.extend(keep)
    return nms_dets

def merge_connected_boxes_by_class(detections, merge_iou_threshold):
    merged = []
    if not detections:
        return []

    class_indices = set([d['class_idx'] for d in detections])
    for class_idx in class_indices:
        class_dets = [d for d in detections if d['class_idx'] == class_idx]
        used = set()
        groups = []
        for i, det in enumerate(class_dets):
            if i in used:
                continue
            group = [det]
            used.add(i)
            changed = True
            while changed:
                changed = False
                newly_added = []
                for j, other in enumerate(class_dets):
                    if j in used:
                        continue
                    if any(compute_iou(d['bbox'], other['bbox']) > merge_iou_threshold for d in group):
                        newly_added.append((j, other))
                
                if newly_added:
                    for j, other in newly_added:
                        group.append(other)
                        used.add(j)
                    changed = True
            groups.append(group)
            
        for group in groups:
            tops = [d['bbox'][0] for d in group]
            bottoms = [d['bbox'][1] for d in group]
            lefts = [d['bbox'][2] for d in group]
            rights = [d['bbox'][3] for d in group]
            merged_box = [min(tops), max(bottoms), min(lefts), max(rights)]
            max_score = max(d['score'] for d in group)
            merged.append({"bbox": merged_box, "class_idx": class_idx, "score": max_score})
    return merged

def ObjectDet(img, threshold, nms_threshold, merge_iou_threshold):
    # img ‡∏£‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô BGR ‡πÅ‡∏•‡πâ‡∏ß (‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô Main UI)
    
    # ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå Sliding Window
    box_size_y, box_size_x, step_size = 500, 500, 50
    resize_input_y, resize_input_x = 64, 64 # ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
    img_h, img_w = img.shape[:2]

    coords = []
    patches = []
    
    # Sliding Window
    for i in range(0, img_h - box_size_y + 1, step_size):
        for j in range(0, img_w - box_size_x + 1, step_size):
            img_patch = img[i:i+box_size_y, j:j+box_size_x]
            
            # Check Brightness (‡∏Å‡∏£‡∏≠‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏î‡∏≥/‡∏°‡∏∑‡∏î‡∏≠‡∏≠‡∏Å ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏†‡∏≤‡∏£‡∏∞‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì)
            brightness = np.mean(cv2.cvtColor(img_patch, cv2.COLOR_BGR2GRAY))
            if brightness < 50:
                continue
                
            img_patch_resized = cv2.resize(img_patch, (resize_input_y, resize_input_x), interpolation=cv2.INTER_AREA)
            patches.append(img_patch_resized)
            coords.append((i, j))

    if not patches:
        return img # ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏™‡∏ß‡πà‡∏≤‡∏á‡∏û‡∏≠ ‡∏´‡∏£‡∏∑‡∏≠‡∏†‡∏≤‡∏û‡πÄ‡∏•‡πá‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ

    patches = np.array(patches)
    
    # Prediction
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏´‡∏•‡∏î‡∏°‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á
    if model is None:
        return img
        
    y_out = model.predict(patches, batch_size=64, verbose=0)
    
    detections = []
    for idx, pred in enumerate(y_out):
        for class_idx in range(len(class_label)):
            score = pred[class_idx]
            # class_idx != 0 ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤ 0 ‡∏Ñ‡∏∑‡∏≠ Background/Artifact
            if score > threshold and class_idx != 0:
                a, c = coords[idx]
                b, d = a + box_size_y, c + box_size_x
                detections.append({"bbox": [a, b, c, d], "score": float(score), "class_idx": class_idx})

    # NMS
    nms_detections = nms(detections, iou_threshold=nms_threshold)
    
    # Merge Boxes
    if merge_iou_threshold is not None and merge_iou_threshold > 0:
        final_detections = merge_connected_boxes_by_class(nms_detections, merge_iou_threshold=merge_iou_threshold)
    else:
        final_detections = nms_detections

    # Draw Boxes
    img_output = img.copy()
    colors = [(0,255,0), (255,0,0), (0,0,255), (0,255,255), (255,0,255), (255,255,0)]
    
    for det in final_detections:
        a, b, c, d = det['bbox']
        class_idx = det['class_idx']
        label = f"{class_label[class_idx]}: {det['score']:.2f}"
        color = colors[class_idx % len(colors)]
        img_output = drawbox(img_output, label, a, b, c, d, color)
        
    return img_output

# --- 4. Streamlit UI Flow (Section Logic) ---

if add_selectbox == "‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å/‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡πÄ‡∏Ç‡πá‡∏°‡∏´‡∏°‡∏∏‡∏î":
    st.markdown("## üìö ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡πÄ‡∏Ç‡πá‡∏°‡∏´‡∏°‡∏∏‡∏î")
    st.markdown("""
    **‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡πÄ‡∏Ç‡πá‡∏°‡∏´‡∏°‡∏∏‡∏î (_Enterobius vermicularis_)** ‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢‡πÉ‡∏ô‡πÄ‡∏î‡πá‡∏Å‡∏ó‡∏±‡πà‡∏ß‡πÇ‡∏•‡∏Å 
    
    ### ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
    ‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡∏ï‡∏±‡∏ß‡πÄ‡∏°‡∏µ‡∏¢‡∏à‡∏∞‡∏ß‡∏≤‡∏á‡πÑ‡∏Ç‡πà‡∏£‡∏≠‡∏ö‡πÜ ‡∏ó‡∏ß‡∏≤‡∏£‡∏´‡∏ô‡∏±‡∏Å‡πÉ‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏•‡∏≤‡∏á‡∏Ñ‡∏∑‡∏ô ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏î‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡∏±‡∏ô ‡πÑ‡∏Ç‡πà‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡∏°‡∏µ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏∑‡∏≠‡∏£‡∏π‡∏õ‡πÑ‡∏Ç‡πà‡∏ó‡∏µ‡πà‡∏î‡πâ‡∏≤‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÅ‡∏ö‡∏ô
    
    ### ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£
    * ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡∏±‡∏ô‡∏ö‡∏£‡∏¥‡πÄ‡∏ß‡∏ì‡∏ó‡∏ß‡∏≤‡∏£‡∏´‡∏ô‡∏±‡∏Å (‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏≠‡∏ô‡∏Å‡∏•‡∏≤‡∏á‡∏Ñ‡∏∑‡∏ô)
    * ‡∏ô‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏ö‡πÑ‡∏°‡πà‡∏™‡∏ô‡∏¥‡∏ó ‡∏´‡∏á‡∏∏‡∏î‡∏´‡∏á‡∏¥‡∏î
    * ‡∏õ‡∏ß‡∏î‡∏ó‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Ñ‡∏£‡∏≤‡∏ß ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏•‡∏∑‡πà‡∏ô‡πÑ‡∏™‡πâ
    
    ### ‡∏Å‡∏≤‡∏£‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô
    1.  ‡∏•‡πâ‡∏≤‡∏á‡∏°‡∏∑‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Å‡πà‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏ó‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏´‡πâ‡∏≠‡∏á‡∏ô‡πâ‡∏≥
    2.  ‡∏ï‡∏±‡∏î‡πÄ‡∏•‡πá‡∏ö‡πÉ‡∏´‡πâ‡∏™‡∏±‡πâ‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏∞‡∏™‡∏°‡∏Ç‡∏≠‡∏á‡πÑ‡∏Ç‡πà‡∏û‡∏¢‡∏≤‡∏ò‡∏¥
    3.  ‡∏ã‡∏±‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ô‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏∑‡πâ‡∏≠‡∏ú‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏ô‡πâ‡∏≥‡∏£‡πâ‡∏≠‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡∏à‡∏≥
    
    **‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô:** ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÇ‡∏õ‡∏£‡∏î‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
    """)

elif add_selectbox == "üîé AI detection":
    st.markdown("## üîé AI Detection (‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏´‡∏≤‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡πÄ‡∏Ç‡πá‡∏°‡∏´‡∏°‡∏∏‡∏î)")
    st.markdown("‡πÇ‡∏õ‡∏£‡∏î‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏à‡∏∏‡∏•‡∏ó‡∏£‡∏£‡∏®‡∏ô‡πå‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏´‡∏≤‡πÑ‡∏Ç‡πà‡∏û‡∏¢‡∏≤‡∏ò‡∏¥ (Tape Test/Swab Test) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ AI ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")

    # --- üìå Fixed Parameters (‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏á‡∏ó‡∏µ‡πà) ---
    # ‡πÄ‡∏≠‡∏≤ Sliders ‡∏≠‡∏≠‡∏Å‡πÅ‡∏•‡∏∞‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
    detection_threshold = 0.95
    nms_threshold = 0
    merge_iou_threshold = 0
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡πà‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ó‡∏£‡∏≤‡∏ö‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô (Optional: ‡∏•‡∏ö‡∏≠‡∏≠‡∏Å‡πÑ‡∏î‡πâ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô)
    st.info(f"‚öôÔ∏è **System Parameters:** Confidence > {detection_threshold}, NMS = {nms_threshold}, Merge = {merge_iou_threshold}")

    uploaded_file = st.file_uploader("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (PNG, JPG, JPEG, TIF)", type=["png", "jpg", "jpeg", "tif"])
    
    if uploaded_file is not None:
        try:
            # Read the file from the uploader
            image = Image.open(uploaded_file)
            image_np = np.array(image.convert("RGB")) # Ensure it's 3-channel (RGB)
            
            # Convert RGB to BGR for OpenCV processing (mandatory for cv2 functions)
            image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)

            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö")
                st.image(image_np, caption=uploaded_file.name, use_column_width=True)

            if model is not None: # Check if model loaded successfully
                # Perform detection - ‚ùó IMPORTANT: Pass the required arguments
                with st.spinner('‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏ß‡∏¢ AI...'):
                    output_img_bgr = ObjectDet(image_bgr, detection_threshold, nms_threshold, merge_iou_threshold)
                
                # Convert the result back to RGB for Streamlit display
                output_img_rgb = cv2.cvtColor(output_img_bgr, cv2.COLOR_BGR2RGB)
                
                with col2:
                    st.subheader("‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
                    st.image(output_img_rgb, caption="‡∏†‡∏≤‡∏û‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏Ç‡πà‡∏û‡∏¢‡∏≤‡∏ò‡∏¥ (‡∏ñ‡πâ‡∏≤‡∏û‡∏ö)", use_column_width=True)
            else:
                with col2:
                    st.subheader("‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
                    # Warning handled by load_model function, but this acts as a fallback
                    st.warning("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏î‡πâ ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• ('ev_cnn_mobile.keras').")

        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û: {e}")

elif add_selectbox == "Dataset":
    st.markdown("## üìä Dataset")
    st.write("‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Dataset (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)")
