import streamlit as st
import cv2
import numpy as np
import tensorflow as tf
from PIL import Image
'''
st.set_page_config(
    page_title="Pinworm Disease Diagnosis",
    layout="wide",
    initial_sidebar_state="expanded"
)
st.title("üî¨ Pinworm Disease Diagnosis App")
st.header("‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö!")
st.markdown("""
‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö **‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡πÄ‡∏Ç‡πá‡∏°‡∏´‡∏°‡∏∏‡∏î (_Enterobius vermicularis_)**
‡πÇ‡∏õ‡∏£‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏°‡∏ô‡∏π‡∏ó‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£:
* **üìö ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡πÄ‡∏Ç‡πá‡∏°‡∏´‡∏°‡∏∏‡∏î:** ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ, ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£, ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô
* **üîé AI detection:** ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏à‡∏∏‡∏•‡∏ó‡∏£‡∏£‡∏®‡∏ô‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏´‡∏≤‡πÑ‡∏Ç‡πà‡∏û‡∏¢‡∏≤‡∏ò‡∏¥
""")
# Using object notation
add_selectbox = st.sidebar.selectbox(
    "How would you like to be contacted?",
    ("‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡πÄ‡∏Ç‡πá‡∏°‡∏´‡∏°‡∏∏‡∏î", "AI detection")
)

#--------------------------------------------------------------------------------------------------------------
model_path = 'ev_cnn_mobile.keras'
model = tf.keras.models.load_model(model_path, custom_objects={'mse': tf.keras.losses.MeanSquaredError()})
    
class_label = ["Artifact", "Ev eggs"]

def drawbox(img, label, a, b, c, d, color):
  image = cv2.rectangle(img, (c, a), (d, b), (255, 0, 0), 3)
  image = cv2.putText(image, label, (c, a - 10), cv2.FONT_HERSHEY_TRIPLEX, 3, (255, 0, 0), 3)
  return image

def compute_iou(box1, box2):
  y1 = max(box1[0], box2[0])
  y2 = min(box1[1], box2[1])
  x1 = max(box1[2], box2[2])
  x2 = min(box1[3], box2[3])
  inter_w = max(0, x2 - x1)
  inter_h = max(0, y2 - y1)
  inter_area = inter_w * inter_h
  box1_area = (box1[1] - box1[0]) * (box1[3] - box1[2])
  box2_area = (box2[1] - box2[0]) * (box2[3] - box2[2])
  union_area = box1_area + box2_area - inter_area
  if union_area == 0:
    return 0
  return inter_area / union_area

def nms(detections, iou_threshold):
  nms_dets = []
  for class_idx in set([d['class_idx'] for d in detections]):
    class_dets = [d for d in detections if d['class_idx'] == class_idx]
    class_dets = sorted(class_dets, key=lambda x: x['score'], reverse=True)
    keep = []
    while class_dets:
      curr = class_dets.pop(0)
      keep.append(curr)
      class_dets = [
        d for d in class_dets
        if compute_iou(curr['bbox'], d['bbox']) < iou_threshold
      ]
    nms_dets.extend(keep)
  return nms_dets

def merge_connected_boxes_by_class(detections, merge_iou_threshold):
  merged = []
  for class_idx in set([d['class_idx'] for d in detections]):
    class_dets = [d for d in detections if d['class_idx'] == class_idx]
    used = set()
    groups = []
    for i, det in enumerate(class_dets):
      if i in used:
        continue
      group = [det]
      used.add(i)
      changed = True
      while changed:
        changed = False
        for j, other in enumerate(class_dets):
          if j in used:
            continue
          if any(compute_iou(d['bbox'], other['bbox']) > merge_iou_threshold for d in group):
            group.append(other)
            used.add(j)
            changed = True
      groups.append(group)
    for group in groups:
      tops = [d['bbox'][0] for d in group]
      bottoms = [d['bbox'][1] for d in group]
      lefts = [d['bbox'][2] for d in group]
      rights = [d['bbox'][3] for d in group]
      merged_box = [min(tops), max(bottoms), min(lefts), max(rights)]
      max_score = max(d['score'] for d in group)
      merged.append({"bbox": merged_box, "class_idx": class_idx, "score": max_score})
  return merged

def ObjectDet(img, threshold, nms_threshold, merge_iou_threshold):
  box_size_y, box_size_x, step_size = 500, 500, 50
  resize_input_y, resize_input_x = 64, 64
  img_h, img_w = img.shape[:2]

  coords = []
  patches = []
  for i in range(0, img_h - box_size_y + 1, step_size):
    for j in range(0, img_w - box_size_x + 1, step_size):
      img_patch = img[i:i+box_size_y, j:j+box_size_x]
      brightness = np.mean(cv2.cvtColor(img_patch, cv2.COLOR_BGR2GRAY))
      if brightness < 50:
        continue
      img_patch = cv2.resize(img_patch, (resize_input_y, resize_input_x), interpolation=cv2.INTER_AREA)
      patches.append(img_patch)
      coords.append((i, j))

  patches = np.array(patches)
  y_out = model.predict(patches, batch_size=64, verbose=0)
  detections = []
  for idx, pred in enumerate(y_out):
    for class_idx in range(len(class_label)):
      score = pred[class_idx]
      if score > threshold and class_idx != 0:
        a, c = coords[idx]
        b, d = a + box_size_y, c + box_size_x
        detections.append({"bbox": [a, b, c, d], "score": float(score), "class_idx": class_idx})

  nms_detections = nms(detections, iou_threshold=nms_threshold)
  if merge_iou_threshold is not None and merge_iou_threshold > 0:
    merged_detections = merge_connected_boxes_by_class(nms_detections, merge_iou_threshold=merge_iou_threshold)
  else:
    merged_detections = nms_detections

  img_output = img.copy()
  colors = [(0,255,0), (255,0,0), (0,0,255), (0,255,255), (255,0,255), (255,255,0)]
  for det in merged_detections:
    a, b, c, d = det['bbox']
    class_idx = det['class_idx']
    label = f"{class_label[class_idx]}: {det['score']:.2f}"
    color = colors[class_idx % len(colors)]
    img_output = drawbox(img_output, label, a, b, c, d, color)
  return img_output
#--------------------------------------------------------------------------------------------------------------

uploaded_file = st.file_uploader("Choose an image file", type=["png", "jpg", "jpeg", "tif"])
if uploaded_file is not None:
    try:
        image = np.array(Image.open(uploaded_file))
        if image.ndim == 2:
            image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)

        st.image(image, caption="Uploaded Image")

        output_img = ObjectDet(image, 0.99, 0.2, 0.3)
        st.image(output_img, caption="Processed Image")

    except Exception as e:
        st.error(f"Error loading image: {e}")
'''

# -------------------------------------------------------------
# üß© CONFIG PAGE
# -------------------------------------------------------------
st.set_page_config(
    page_title="Pinworm Disease Diagnosis",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("üî¨ Pinworm Disease Diagnosis App")
st.header("‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö!")

st.markdown("""
‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö  
**‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡πÄ‡∏Ç‡πá‡∏°‡∏´‡∏°‡∏∏‡∏î (_Enterobius vermicularis_)** ü™±  
‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏õ‡∏±‡∏ç‡∏ç‡∏≤‡∏õ‡∏£‡∏∞‡∏î‡∏¥‡∏©‡∏ê‡πå (AI) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏£‡∏ß‡∏à‡∏´‡∏≤‡∏†‡∏≤‡∏û‡πÑ‡∏Ç‡πà‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏à‡∏∏‡∏•‡∏ó‡∏£‡∏£‡∏®‡∏ô‡πå
""")

# -------------------------------------------------------------
# üß≠ SIDEBAR MENU
# -------------------------------------------------------------
add_selectbox = st.sidebar.radio(
    "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏°‡∏ô‡∏π‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£:",
    ("üìö ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡πÄ‡∏Ç‡πá‡∏°‡∏´‡∏°‡∏∏‡∏î", "ü§ñ AI detection")
)

# -------------------------------------------------------------
# üìò KNOWLEDGE SECTION
# -------------------------------------------------------------
if add_selectbox == "üìö ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡πÄ‡∏Ç‡πá‡∏°‡∏´‡∏°‡∏∏‡∏î":
    st.subheader("ü¶† ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡πÄ‡∏Ç‡πá‡∏°‡∏´‡∏°‡∏∏‡∏î (_Enterobius vermicularis_)")
    st.image(
        "https://upload.wikimedia.org/wikipedia/commons/2/2d/Enterobius_vermicularis_life_cycle.png",
        caption="‡∏ß‡∏á‡∏à‡∏£‡∏ä‡∏µ‡∏ß‡∏¥‡∏ï‡∏Ç‡∏≠‡∏á‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡πÄ‡∏Ç‡πá‡∏°‡∏´‡∏°‡∏∏‡∏î (CDC, 2023)",
        use_container_width=True
    )

    st.markdown("""
### üîç ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ  
- ‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡πÄ‡∏Ç‡πá‡∏°‡∏´‡∏°‡∏∏‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡∏ï‡∏±‡∏ß‡∏Å‡∏•‡∏°‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å ‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß ‡∏¢‡∏≤‡∏ß‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 0.5 ‚Äì 1 ‡πÄ‡∏ã‡∏ô‡∏ï‡∏¥‡πÄ‡∏°‡∏ï‡∏£  
- ‡∏û‡∏ö‡πÑ‡∏î‡πâ‡∏ö‡πà‡∏≠‡∏¢‡πÉ‡∏ô‡πÄ‡∏î‡πá‡∏Å ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÉ‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏Ç‡∏≤‡∏†‡∏¥‡∏ö‡∏≤‡∏•‡πÑ‡∏°‡πà‡∏î‡∏µ  
- ‡πÑ‡∏Ç‡πà‡∏Ç‡∏≠‡∏á‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡∏°‡∏µ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡πÉ‡∏™ ‡∏£‡∏π‡∏õ‡∏£‡∏µ ‡πÅ‡∏•‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏™‡∏¥‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏•‡πá‡∏ö‡∏°‡∏∑‡∏≠‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢  

### ‚ö†Ô∏è ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢  
- ‡∏Ñ‡∏±‡∏ô‡∏ö‡∏£‡∏¥‡πÄ‡∏ß‡∏ì‡∏ó‡∏ß‡∏≤‡∏£‡∏´‡∏ô‡∏±‡∏Å ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏≠‡∏ô‡∏Å‡∏•‡∏≤‡∏á‡∏Ñ‡∏∑‡∏ô  
- ‡∏ô‡∏≠‡∏ô‡πÑ‡∏°‡πà‡∏´‡∏•‡∏±‡∏ö ‡∏´‡∏á‡∏∏‡∏î‡∏´‡∏á‡∏¥‡∏î  
- ‡∏≠‡∏≤‡∏à‡∏û‡∏ö‡πÑ‡∏Ç‡πà‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡πÉ‡∏ô‡∏≠‡∏∏‡∏à‡∏à‡∏≤‡∏£‡∏∞‡∏´‡∏£‡∏∑‡∏≠‡∏ö‡∏£‡∏¥‡πÄ‡∏ß‡∏ì‡∏Å‡πâ‡∏ô  

### üß´ ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢  
- ‡∏ß‡∏¥‡∏ò‡∏µ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏î‡πâ‡∏ß‡∏¢ **cellophane tape test** (‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏õ‡πÉ‡∏™‡πÅ‡∏ï‡∏∞‡∏ö‡∏£‡∏¥‡πÄ‡∏ß‡∏ì‡∏£‡∏≠‡∏ö‡∏ó‡∏ß‡∏≤‡∏£‡∏´‡∏ô‡∏±‡∏Å‡∏ï‡∏≠‡∏ô‡πÄ‡∏ä‡πâ‡∏≤)  
- ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏à‡∏∏‡∏•‡∏ó‡∏£‡∏£‡∏®‡∏ô‡πå‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏´‡πá‡∏ô‡πÑ‡∏Ç‡πà‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡∏£‡∏π‡∏õ‡∏£‡∏µ‡∏°‡∏µ‡∏ù‡∏≤‡πÅ‡∏ö‡∏ô‡∏î‡πâ‡∏≤‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á  

### üßç‚Äç‚ôÄÔ∏è ‡∏Å‡∏≤‡∏£‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô  
- ‡∏•‡πâ‡∏≤‡∏á‡∏°‡∏∑‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Å‡πà‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏ó‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏´‡πâ‡∏≠‡∏á‡∏ô‡πâ‡∏≥  
- ‡∏ï‡∏±‡∏î‡πÄ‡∏•‡πá‡∏ö‡πÉ‡∏´‡πâ‡∏™‡∏±‡πâ‡∏ô ‡πÑ‡∏°‡πà‡πÅ‡∏Ñ‡∏∞‡∏Å‡πâ‡∏ô  
- ‡∏ã‡∏±‡∏Å‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ú‡πâ‡∏≤‡∏õ‡∏π‡∏ó‡∏µ‡πà‡∏ô‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏∑‡πâ‡∏≠‡∏ú‡πâ‡∏≤‡∏ö‡πà‡∏≠‡∏¢ ‡πÜ  
- ‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡πÉ‡∏ô‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏£‡∏±‡∏ß‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏û‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡πÄ‡∏ä‡∏∑‡πâ‡∏≠  

### üíä ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤  
- ‡πÉ‡∏ä‡πâ‡∏¢‡∏≤‡∏ñ‡πà‡∏≤‡∏¢‡∏û‡∏¢‡∏≤‡∏ò‡∏¥ ‡πÄ‡∏ä‡πà‡∏ô **Mebendazole** ‡∏´‡∏£‡∏∑‡∏≠ **Albendazole** ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Ç‡∏≠‡∏á‡πÅ‡∏û‡∏ó‡∏¢‡πå  
- ‡∏Ñ‡∏ß‡∏£‡∏Å‡∏¥‡∏ô‡∏ã‡πâ‡∏≥‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å 2 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ü‡πà‡∏≤‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡∏ó‡∏µ‡πà‡∏ü‡∏±‡∏Å‡πÉ‡∏´‡∏°‡πà  
    """)

    st.info("üí° ‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö: ‡∏Å‡∏≤‡∏£‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏Å‡∏©‡∏≤ ‚Äî ‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡∏•‡πâ‡∏≤‡∏á‡∏°‡∏∑‡∏≠‡πÄ‡∏™‡∏°‡∏≠!")

# -------------------------------------------------------------
# ü§ñ AI DETECTION SECTION
# -------------------------------------------------------------
elif add_selectbox == "ü§ñ AI detection":
    st.subheader("üß† ‡∏£‡∏∞‡∏ö‡∏ö AI ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏Ç‡πà‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡πÄ‡∏Ç‡πá‡∏°‡∏´‡∏°‡∏∏‡∏î")

    st.markdown("""
    ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏à‡∏∏‡∏•‡∏ó‡∏£‡∏£‡∏®‡∏ô‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏ö AI ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå  
    ‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡∏ñ‡∏π‡∏Å‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ **Convolutional Neural Network (CNN)**  
    ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏†‡∏≤‡∏û‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô  
    - **Ev eggs (‡πÑ‡∏Ç‡πà‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡πÄ‡∏Ç‡πá‡∏°‡∏´‡∏°‡∏∏‡∏î)** ‡∏´‡∏£‡∏∑‡∏≠  
    - **Artifact (‡∏™‡∏¥‡πà‡∏á‡πÅ‡∏õ‡∏•‡∏Å‡∏õ‡∏•‡∏≠‡∏°)**

    **‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:**
    1. ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û (.jpg, .png, .tif)
    2. ‡∏£‡∏≠‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
    3. ‡∏†‡∏≤‡∏û‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÑ‡∏Ç‡πà‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö  
    """)

    # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
    model_path = 'ev_cnn_mobile.keras'
    model = tf.keras.models.load_model(model_path, custom_objects={'mse': tf.keras.losses.MeanSquaredError()})
    class_label = ["Artifact", "Ev eggs"]

    # ---------------------- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô ----------------------
    def drawbox(img, label, a, b, c, d, color):
        image = cv2.rectangle(img, (c, a), (d, b), color, 3)
        image = cv2.putText(image, label, (c, a - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
        return image

    def compute_iou(box1, box2):
        y1 = max(box1[0], box2[0])
        y2 = min(box1[1], box2[1])
        x1 = max(box1[2], box2[2])
        x2 = min(box1[3], box2[3])
        inter_w = max(0, x2 - x1)
        inter_h = max(0, y2 - y1)
        inter_area = inter_w * inter_h
        box1_area = (box1[1] - box1[0]) * (box1[3] - box1[2])
        box2_area = (box2[1] - box2[0]) * (box2[3] - box2[2])
        union_area = box1_area + box2_area - inter_area
        return inter_area / union_area if union_area else 0

    def nms(detections, iou_threshold):
        nms_dets = []
        for class_idx in set([d['class_idx'] for d in detections]):
            class_dets = [d for d in detections if d['class_idx'] == class_idx]
            class_dets = sorted(class_dets, key=lambda x: x['score'], reverse=True)
            keep = []
            while class_dets:
                curr = class_dets.pop(0)
                keep.append(curr)
                class_dets = [
                    d for d in class_dets
                    if compute_iou(curr['bbox'], d['bbox']) < iou_threshold
                ]
            nms_dets.extend(keep)
        return nms_dets

    def merge_connected_boxes_by_class(detections, merge_iou_threshold):
        merged = []
        for class_idx in set([d['class_idx'] for d in detections]):
            class_dets = [d for d in detections if d['class_idx'] == class_idx]
            used = set()
            groups = []
            for i, det in enumerate(class_dets):
                if i in used:
                    continue
                group = [det]
                used.add(i)
                changed = True
                while changed:
                    changed = False
                    for j, other in enumerate(class_dets):
                        if j in used:
                            continue
                        if any(compute_iou(d['bbox'], other['bbox']) > merge_iou_threshold for d in group):
                            group.append(other)
                            used.add(j)
                            changed = True
                groups.append(group)
            for group in groups:
                tops = [d['bbox'][0] for d in group]
                bottoms = [d['bbox'][1] for d in group]
                lefts = [d['bbox'][2] for d in group]
                rights = [d['bbox'][3] for d in group]
                merged_box = [min(tops), max(bottoms), min(lefts), max(rights)]
                max_score = max(d['score'] for d in group)
                merged.append({"bbox": merged_box, "class_idx": class_idx, "score": max_score})
        return merged

    def ObjectDet(img, threshold, nms_threshold, merge_iou_threshold):
        box_size_y, box_size_x, step_size = 500, 500, 50
        resize_input_y, resize_input_x = 64, 64
        img_h, img_w = img.shape[:2]
        coords = []
        patches = []
        for i in range(0, img_h - box_size_y + 1, step_size):
            for j in range(0, img_w - box_size_x + 1, step_size):
                img_patch = img[i:i+box_size_y, j:j+box_size_x]
                brightness = np.mean(cv2.cvtColor(img_patch, cv2.COLOR_BGR2GRAY))
                if brightness < 50:
                    continue
                img_patch = cv2.resize(img_patch, (resize_input_y, resize_input_x))
                patches.append(img_patch)
                coords.append((i, j))
        if not patches:
            return img
        patches = np.array(patches)
        y_out = model.predict(patches, batch_size=64, verbose=0)
        detections = []
        for idx, pred in enumerate(y_out):
            for class_idx in range(len(class_label)):
                score = pred[class_idx]
                if score > threshold and class_idx != 0:
                    a, c = coords[idx]
                    b, d = a + box_size_y, c + box_size_x
                    detections.append({"bbox": [a, b, c, d], "score": float(score), "class_idx": class_idx})
        nms_detections = nms(detections, iou_threshold=nms_threshold)
        merged_detections = merge_connected_boxes_by_class(nms_detections, merge_iou_threshold)
        img_output = img.copy()
        colors = [(0,255,0), (255,0,0), (0,0,255)]
        for det in merged_detections:
            a, b, c, d = det['bbox']
            label = f"{class_label[det['class_idx']]}: {det['score']:.2f}"
            img_output = drawbox(img_output, label, a, b, c, d, colors[det['class_idx'] % len(colors)])
        return img_output

    # ---------------------- Upload Section ----------------------
    uploaded_file = st.file_uploader("üì§ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏à‡∏∏‡∏•‡∏ó‡∏£‡∏£‡∏®‡∏ô‡πå", type=["png", "jpg", "jpeg", "tif"])
    if uploaded_file is not None:
        try:
            image = np.array(Image.open(uploaded_file))
            if image.ndim == 2:
                image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
            st.image(image, caption="üì∏ ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î", use_container_width=True)
            st.info("üîé ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ...")
            output_img = ObjectDet(image, 0.99, 0.2, 0.3)
            st.image(output_img, caption="‚úÖ ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö", use_container_width=True)
        except Exception as e:
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û: {e}")


